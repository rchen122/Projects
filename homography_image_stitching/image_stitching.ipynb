{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import skimage\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial import distance\n",
    "import scipy \n",
    "from starter import *\n",
    "from skimage import transform\n",
    "\n",
    "def plot_inlier_matches(ax, img1, img2, inliers):\n",
    "    \"\"\"\n",
    "    Plot the matches between two images according to the matched keypoints\n",
    "    :param ax: plot handle\n",
    "    :param img1: left image\n",
    "    :param img2: right image\n",
    "    :inliers: x,y in the first image and x,y in the second image (Nx4)\n",
    "    \"\"\"\n",
    "    inliers = inliers.reshape(-1,4)\n",
    "    print(inliers.shape)\n",
    "    res = np.hstack([img1, img2])\n",
    "    ax.set_aspect('equal')\n",
    "    ax.imshow(res, cmap='gray')\n",
    "    \n",
    "    ax.plot(inliers[:,0], inliers[:,1], '+r')\n",
    "    ax.plot(inliers[:,2] + img1.shape[1], inliers[:,3], '+r')\n",
    "    ax.plot([inliers[:,0], inliers[:,2] + img1.shape[1]],\n",
    "            [inliers[:,1], inliers[:,3]], 'r', linewidth=0.4)\n",
    "    ax.axis('off')\n",
    "    \n",
    "#Load both Images, convert to double and grayscale\n",
    "left_image = cv2.imread(\"pier1.jpg\")\n",
    "middle_image = cv2.imread(\"pier2.jpg\")\n",
    "right_image = cv2.imread(\"pier3.jpg\")\n",
    "\n",
    "left_gray = cv2.cvtColor(left_image, cv2.COLOR_BGR2GRAY)\n",
    "middle_gray = cv2.cvtColor(middle_image, cv2.COLOR_BGR2GRAY)\n",
    "right_gray = cv2.cvtColor(right_image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "\n",
    "def RANSAC_loop(matches, num_iterations, inlier_threshold):\n",
    "    \"\"\"\n",
    "    RANSAC loop:\n",
    "    1. Randomly select a seed group of matches (4 matches to start)\n",
    "    2. Compute transformation from seed group\n",
    "    3. Find inliers to this transformation\n",
    "    4. If the number of inliers is sufficiently large, re-compute least-squares\n",
    "    estimate of transformation on all of the inliers\n",
    "    â€¢ At the end, keep the transformation with the largest number of inliers\n",
    "    \"\"\"\n",
    "    max_inliers = 0 \n",
    "    best_H = None\n",
    "    all_inliers = None\n",
    "    for i in range(num_iterations):\n",
    "        #1\n",
    "        seed_indices = np.random.choice(matches.shape[0], 4, replace=False)\n",
    "        seed_group = matches[seed_indices]\n",
    "\n",
    "        points_left = np.array([match[0] for match in seed_group])\n",
    "        points_right = np.array([match[1] for match in seed_group])\n",
    "\n",
    "        #2 Compute Homography\n",
    "        A = []\n",
    "        for i in range(len(points_left)):\n",
    "            x1, y1 = points_left[i]\n",
    "            x2, y2 = points_right[i]\n",
    "\n",
    "            A.append([0, 0, 0, x1, y1, 1, -y2 * x1, -y2 * y1, -y2]) \n",
    "            A.append([x1, y1, 1, 0, 0, 0, -x2 * x1, -x2 * y1, -x2])  \n",
    "        \n",
    "        A = np.array(A)\n",
    "        U, S, V = np.linalg.svd(A)\n",
    "        H = V[-1] \n",
    "        H = H.reshape(3, 3) \n",
    "\n",
    "        points1_homogeneous = cv2.convertPointsToHomogeneous(np.array([m[0] for m in matches])).reshape(-1, 3) #Convert to homogeneous coordinates\n",
    "        transformed_points = (H @ points1_homogeneous.T).T\n",
    "        transformed_points /= transformed_points[:, 2].reshape(-1, 1)  # Convert from homogeneous coordinates\n",
    "\n",
    "        # Calculate the distances to the corresponding points in right image\n",
    "        points2_homogeneous = np.array([m[1] for m in matches])\n",
    "        distances = np.sqrt(np.sum((transformed_points[:, :2] - points2_homogeneous) ** 2, axis=1))\n",
    "\n",
    "        # Determine inliers\n",
    "        inlier_mask = distances < inlier_threshold\n",
    "        inliers_count = np.sum(inlier_mask)\n",
    "\n",
    "        #4\n",
    "        if inliers_count > max_inliers:\n",
    "            max_inliers = inliers_count\n",
    "            best_H = H\n",
    "            all_inliers = matches[inlier_mask]\n",
    "\n",
    "\n",
    "    # Calculate average residual for inliers\n",
    "    if all_inliers is not None:\n",
    "        inlier_points1 = np.array([m[0] for m in all_inliers])\n",
    "        inlier_points2 = np.array([m[1] for m in all_inliers])\n",
    "        \n",
    "        transformed_inlier_points1 = (best_H @ cv2.convertPointsToHomogeneous(inlier_points1).reshape(-1,3).T).T\n",
    "        transformed_inlier_points1 /= transformed_inlier_points1[:, 2].reshape(-1, 1)  # Normalize\n",
    "        \n",
    "        residuals = np.sqrt(np.sum((transformed_inlier_points1[:, :2] - inlier_points2) ** 2, axis=1))\n",
    "        average_residual = np.mean(residuals)\n",
    "    else:\n",
    "        average_residual = None\n",
    "\n",
    "    return best_H, max_inliers, average_residual, all_inliers\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3&4: Extract keypoints and neighborhoods using SIFT descriptors\n",
    "def get_keypoints_and_matches(left_gray, right_gray):\n",
    "    sift_left = cv2.SIFT_create()\n",
    "    sift_middle = cv2.SIFT_create()\n",
    "    kp_left, des_left= sift_left.detectAndCompute(left_gray, None)\n",
    "    kp_middle, des_right = sift_middle.detectAndCompute(right_gray, None)\n",
    "\n",
    "    kp_left_coords = np.array([kp.pt for kp in kp_left])\n",
    "    kp_right_coords = np.array([kp.pt for kp in kp_middle])\n",
    "\n",
    "    #5 Compute Distances between every desciptor of one image to those of the other. \n",
    "    eucdistance = distance.cdist(des_left, des_right, \"sqeuclidean\")\n",
    "\n",
    "\n",
    "    #Select Putative matches by selecting top few hundred descriptor pairs with smallest pairwise distances\n",
    "    k = 150\n",
    "    flat_indices = np.argsort(eucdistance, axis=None)[:k]\n",
    "    row_indices, col_indices = np.unravel_index(flat_indices, eucdistance.shape)\n",
    "    filtered_matches_top_k = np.array([kp_left[row_indices[i]], kp_right[col_indices[i]]] for i in range(k))\n",
    "    filtered_matches = np.array([(kp_left_coords[row_indices[i]], kp_right_coords[col_indices[i]]) for i in range(k)])\n",
    "    return filtered_matches\n",
    "\n",
    "filtered_matches = get_keypoints_and_matches(left_gray, middle_gray)\n",
    "\n",
    "print(\"Top-k matches found:\", len(filtered_matches))\n",
    "\n",
    "while True:\n",
    "    inlier_threshold = 60\n",
    "    num_iterations = 1000\n",
    "    best_H,  max_inliers, average_residual, all_inliers = RANSAC_loop(filtered_matches, num_iterations=num_iterations, inlier_threshold=inlier_threshold)\n",
    "    if average_residual < 0.4:\n",
    "        break\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20,10))\n",
    "plot_inlier_matches(ax, left_image, middle_image, all_inliers)\n",
    "plt.show()\n",
    "print(f\"Number of inliers: {max_inliers}\")\n",
    "\n",
    "def stitch_image(left_image, right_image, best_H):\n",
    "    h, w = left_image.shape[:2]\n",
    "    h2, w2 = right_image.shape[:2]\n",
    "    corners = np.array([[0, 0], [w, 0], [0, h], [w, h]])\n",
    "\n",
    "    transform_object = skimage.transform.ProjectiveTransform(best_H)\n",
    "    warped_corners = transform_object(corners)\n",
    "\n",
    "    min_coords = warped_corners.min(axis=0)\n",
    "    max_coords = warped_corners.max(axis=0)\n",
    "\n",
    "    translation = transform.AffineTransform(translation=-min_coords)\n",
    "    transformed_H = translation.params @ best_H\n",
    "\n",
    "    output_shape = (\n",
    "        int(max(max_coords[1], h2) - min(min_coords[1], 0)),\n",
    "        int(max(max_coords[0], w2) - min(min_coords[0], 0))\n",
    "    )\n",
    "\n",
    "\n",
    "    canvas = np.zeros((output_shape[0], output_shape[1], 3), dtype=np.uint8)\n",
    "    left_image = cv2.cvtColor(left_image, cv2.COLOR_BGR2RGB)\n",
    "    right_image = cv2.cvtColor(right_image, cv2.COLOR_BGR2RGB)\n",
    "    for channel in range(3):\n",
    "        warped_left_image = transform.warp(left_image[:, :, channel].astype(np.float32)/255, transform.ProjectiveTransform(transformed_H).inverse, output_shape=output_shape)\n",
    "        warped_left_image = (warped_left_image * 255).astype(np.uint8)\n",
    "        canvas[:, :, channel] = warped_left_image\n",
    "        x_offset = int(np.abs(min_coords[0]))\n",
    "        y_offset = int(np.abs(min_coords[1]))\n",
    "        # warped_mask = (warped_left_image > 0)\n",
    "\n",
    "        for y in range(h2):\n",
    "            for x in range(w2):\n",
    "                canvas_y = y + y_offset\n",
    "                canvas_x = x + x_offset\n",
    "                if canvas[canvas_y, canvas_x, channel] > 0:\n",
    "                    # canvas[canvas_y, canvas_x] = (canvas[canvas_y, canvas_x] + right_gray[y, x]) / 2\n",
    "                    canvas[canvas_y, canvas_x, channel] = canvas[canvas_y, canvas_x, channel]\n",
    "                else:\n",
    "                    canvas[canvas_y, canvas_x, channel] = right_image[y, x, channel]\n",
    "    # canvas[int(np.abs(min_coords[1])):int(np.abs(min_coords[1]))+h2, int(np.abs(min_coords[0])):] = right_gray\n",
    "    canvas_final = cv2.cvtColor(canvas, cv2.COLOR_RGB2BGR)\n",
    "    return canvas_final\n",
    "\n",
    "canvas_final = stitch_image(left_image, middle_image, best_H)\n",
    "\n",
    "cv2.imwrite(\"Pier1and2.jpg\", canvas_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Residual: 0.3125340286524681\n",
      "Number of Inliers for complete stitching: 150\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_image = cv2.imread(\"Pier1and2.jpg\")\n",
    "combined_gray = cv2.cvtColor(combined_image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "filtered_matches = get_keypoints_and_matches(combined_gray, right_gray)\n",
    "\n",
    "while True:\n",
    "    inlier_threshold = 60\n",
    "    num_iterations = 1000\n",
    "    best_H,  max_inliers, average_residual, all_inliers = RANSAC_loop(filtered_matches, num_iterations=num_iterations, inlier_threshold=inlier_threshold)\n",
    "    print(f\"Average Residual: {average_residual}\")\n",
    "    if average_residual < 0.4:\n",
    "        break\n",
    "print(f\"Number of Inliers for complete stitching: {max_inliers}\")\n",
    "\n",
    "\n",
    "\n",
    "canvas_final_final = stitch_image(combined_image, right_image, best_H)\n",
    "cv2.imwrite(\"P2_Canvas.jpg\", canvas_final_final)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
